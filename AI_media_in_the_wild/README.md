### Intro

The AI media *in-the-wild* examples were collected through the work of the [Deepfakes Rapid Response Force](https://www.gen-ai.witness.org/deepfakes-rapid-response-force/). This WITNESS initiative connects frontline fact-checkers, journalists, and civil society actors with leading media forensics and deepfake detection experts who provide a timely, evidence-based analysis of potentially AI-manipulated or generated content threatening democracy and human rights.

Cases analysed by the Force demonstrate the challenges presented by the AI-manipulated media shared in real-world high-stakes context, including difficulties stemming from compressed or low-quality media, and the diversity of media types, and gaps in training data for local languages and representations.

### Description

The repository consists of videos, audio recordings and images that were submitted to and analysed by the experts from the Deepfakes Rapid Response Force. Each media type is assigned one of three labels:

* **likely-manipulated**: the expert analysis found evidence of AI manipulation indicating that a piece of media was likely AI-generated or AI-manipulated  
* **likely-authentic**: the expert analysis did not find evidence of AI manipulation indicating that a piece of media is likely authentic  f
* **inconsistent**: the expert analysis could not deliver a conclusive result as to the nature of the content due to factors such as low quality, high compression, length (in cases of video and audio recordings), or the language missing from the training data

### Data collection 

The media content building the *in-the-wild* part of the repository was sourced from submissions provided to WITNESS' Deepfake Rapid Response Force gathered through voluntary submissions from civil society and media stakeholders, predominantly made of publicly available content from social media.
